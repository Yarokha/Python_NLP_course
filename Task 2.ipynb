{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузим нужные модули"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from transformers import pipeline, Trainer, AutoTokenizer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset\n",
    "\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем данные с новостями, где label  0 - Real, а 1 - Fake\n",
    "\n",
    "Подготавливаем датасет с train и test частями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = pd.read_csv(\"fakenews.csv\")\n",
    "X_, X_test, y_, y_test = train_test_split(data_set['text'], data_set['label'], random_state=2023)\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(X_, y_, random_state=2023)\n",
    "\n",
    "dataset =  DatasetDict({'train':Dataset.from_dict({'text':X_train, 'labels':y_train}),\n",
    "                        'eval':Dataset.from_dict({'text':X_eval, 'labels':y_eval}),\n",
    "                        'test':Dataset.from_dict({'text':X_test, 'labels':y_test})})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью pipeline используем предобученную модель Eip/autotrain-real-vs-fake-news-2757281769"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Eip/autotrain-real-vs-fake-news-2757281769\"\n",
    "pipe = pipeline(\"text-classification\", model=model_name, truncation=True)\n",
    "\n",
    "y_pre_trained_predict = pipe(X_test.to_list())\n",
    "y_pre_trained_predict = [ 1 if i['label'] == \"Fake\" else 0 for i in y_pre_trained_predict]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика до обучения выбранной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.71      0.01      0.01       717\n",
      "        Fake       0.43      1.00      0.60       530\n",
      "\n",
      "    accuracy                           0.43      1247\n",
      "   macro avg       0.57      0.50      0.31      1247\n",
      "weighted avg       0.59      0.43      0.26      1247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pre_trained_predict,  target_names=[\"Real\", \"Fake\"]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготавливаем модель к обучению на выбранном датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: \"Real\", 1: \"Fake\"}\n",
    "label2id = {\"Real\": 0, \"Fake\": 1}\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,num_labels=2, id2label=id2label, label2id=label2id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd7d410f3ce443681f8c9c5edb0957c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2804 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2dea158216d4a5995683447867d455e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/935 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06cedade6c8469f919146bad9ee8f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def token_func(data):\n",
    "    return tokenizer(data[\"text\"], truncation=True, padding=\"max_length\")\n",
    "# , return_tensors=\"pt\"\n",
    "tokenized_data = dataset.map(token_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yarok\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "\t\t  output_dir=\"test_trainer\", \n",
    "\t\t  evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data['train'],\n",
    "    eval_dataset=tokenized_data['eval'],\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дообучение и сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205da18713004657886412a45116b6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прверка тестовой выборки на дообученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd74aafc025408f97b9abe16b0f1cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_predictions = trainer.predict(tokenized_data['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика после дообучения выбранной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.83      0.80      0.82       717\n",
      "        Fake       0.75      0.78      0.76       530\n",
      "\n",
      "    accuracy                           0.79      1247\n",
      "   macro avg       0.79      0.79      0.79      1247\n",
      "weighted avg       0.80      0.79      0.79      1247\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_trained_predict = np.argmax(trained_predictions[0], axis=-1) \n",
    "print(classification_report(y_test, y_trained_predict,  target_names=[\"Real\", \"Fake\"]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом дообучение модели позволило улучшить определение типа новости практические в 1.84 раза"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
